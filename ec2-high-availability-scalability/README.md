## Scalability and High Availability Section

* Scalability means that an application / system can handle greater loads by adapting
* There are two kinds of scalability:
  * Vertical Scalability
  * Horizontal Scalability (= elasticity)
* **Scalability is linked but different to High Availability**

#### Vertical Scaling

* Vertically scalability means increasing the size of the instance
* Vertical scaling is very common for non distributed systems, such as a database
* RDS, ElastiCache are services that can scale vertically
* There's usually a limit to how much you can vertically scale (hardware limit)

#### Horizontal Scalability

* Horizontal Scalability means increasing the number of instances / systems for your application
* Horizontal scaling implies distributed systems
* This is very common for web aplications / modern applications
* It's easy to horizontally scale thanks to the cloud (EC2)

#### High Availability

* High Availability usually goes hand in hand with horizontal scaling
* High availability means running your application / system in at least 2 data centers ( == Availability Zones)
* The goal of high availability is to survive a data center loss
* The high availability can be passive (for RDS Multi AZ for example) 
* The high availability can be active (for horizontal scaling)

#### High Availability & Scalability for EC2

* Vertical Scaling: instance size (= scale up / down)
  * From: t2.nano - 0.5G of RAM, 1 vCPU
  * To: u-12tbl.metal - 12.3 TB of RAM, 448 vCPUs
* Horizontal Scaling: increase the number of instances (= scale out / in)
  * Auto Scaling Group
  * Load Balancer
* High Availability: Run instances for the same application across multi AZ
  * Auto Scaling Group multi AZ 
  * Load Balancer is multi AZ

#### Focus on this section:

* Load Balancers
  * Troubleshooting
  * Advanced options and logging
  * CloudWatch integration
* Auto Scaling
  * Troubleshooting
  * Advanced options and logging
  * CloudWatch integration

### Load Balancer

* Load Balancers are servers that forward internet traffic to multiple servers (EC2 Instances) downstream
* Why use a Load Balancer:
  * Spread load across multiple downstream instances
  * Expose a single point of access (DNS) to your application
  * Seamlessly handle failures of downstream instances
  * Do regular health checks to your instances
  * Provide SSL termination (HTTPS) for your websites
  * Enforce stickiness with cookies
  * High availability across zones
  * Separate public traffic from private traffic

#### Why use an EC2 Load Balancer:

* An ELB (EC2 Load Balancer) is a managed load balancer
  * AWS guarantees that it will be working
  * AWS takes care of upgrades, maintenance, high availability
  * AWS provides only a feel configuration options
* It costs less to setup your own load balancer, but it will be a lot more effort on your end
* It is integrated with many AWS offerings / services 

#### Types of Load Balancer on AWS:

* Classic Load Balancer (v1 - old generation) - 2009
* Application Load Balancer (v2 - new generation) - 2016
* Network Load Balancer (v2 - new generation) - 2017
* Overall, it is recommended to use the newer load balancers, as they provide more features
* You can setup **internal** or **external** ELBs

#### Health Checks

* Health Checks are crucial for Load Balancers
* They enable the load balancer to know if instances it forwards traffic to are available to reply to requests
* The health check is done on a port and a route (/health is common)
* If the response is not 200 (OK), then the instance is unhealthy

#### Application Load Balancer (v2)

* Application Load Balancers (Layer 7) allows to:
  * Load balancing to multiple HTTP applications across machines (target groups)
  * Load balancing to multiple applications on the same machine (ex: containers)
  * Load balancing based on route in URL
  * Load balancing based on hostname in URL
* Great for micro services & container-based application (example: Docker & Amazon ECS)
* Has a port mapping feature to redirect to a dynamic port
  * In comparison, we would need to create one Classic Load Balancer per application before.
* **Good to know**:
  * Stickiness can be enabled at the target group level:
    * Same request goes to the same instance
    * Stickiness is directly generated by the ALB (not the application)
  * ALB support HTTP/HTTPS & Websockets protocols
  * The application servers don't see the IP of the client directly
    * The true IP of the client is inserted in the header **X-Forwarded-For**
    * We can also get Port (**X-Forwarded-Port**) and proto (**X-Forwarded-Proto**)

#### Network Load Balancer (v2)

* Network load balancers (Layer 4) allows to:
  * Forward TCP traffic to your instances
  * Handle millions of request per seconds
  * Support for static IP or elastic IP
  * Less latency ~100 ms (vs 400 ms for ALB)
* Network Load Balancers are mostly used for extreme performance and should not be the default load balancer your choose 

#### Load Balancer - Good to know

* Any Load Balancer (CLB, ALB, NLB) has a static host name. Do not resolve and use underlying IP
* LBs can scale but not instantaneously - contact AWS for a "warm-up"
* NLB directly see the client IP
* 4xx errors are client induced errors
* 5xx errors are application induced errors
  * Load Balancer Errors 503 means at capacity or no registered target
* If the LB can't connect ot your application, check your security groups

### Load Balance Stickiness

* Same client is always redirected to the same instance behind a load balancer with stickiness enabled
* Works for CLB & ALB
* The "cookie" used for stickiness has an expiration date you control
* Use case: make sure the user doesn't lose his session data
* Enablind stickiness may bring imbalance to the load over the backend EC2 instances

### Load Balancer for SysOps

* Exam tip: to give a ALB a fixed IP, place it behind an NLB

#### Load Balancer Pre-warming

* ELB scale gradually to traffic
* ELB may fail in case of sudden spike of traffic (10x traffic)
* If you expect high traffic, open a support ticket with AWS to pre-warm your ELB
  * Duration of traffic
  * Expected request per second
  * Size of request (in KB)

#### Load Balancer Error Codes

* Sucessful request: Code 200
* Unsuccessful at client side: 4xx code
  * Error 400: Bad Request
  * Error 401: Unauthorized
  * Error 403: Forbidden
  * Error 460: Client closed connection
  * Error 463: X-Forwarded For header with >30 IP (Similar to malformed request)
* Unsuccessful at server side: 5xx code
  * An error 500 / Internal server error would mean some error on the ELB itself
  * Error 502: Bad Gateway
  * **An error 503/ Service Unavailable**
  * Error 504 / Gateway timeout: probably an issue within the server
  * Error 561: Unauthorized

#### Supporting SSL for Old Browsers

* Common question is: how do we support Legacy Browsers that has an old TLS ( such as TLS 1.0)?
* Answer: change the policy to allow for weaker cipher (e.g. DES-CBC3-SHA for TLS 1.0)
* Note: only a very small % of the internet uses TLS 1.0

#### Load Balancer common troubleshooting

* Check Security Groups
* Check Health Checks
* Sticky sessions may bring "imbalance" on the load balancing side
* For Multi-AZ, make sure cross zone balancing is enabled (CLB)
* Use **Internal** load balancer for private applications that don't need a public access
* Enable Deletion Protection to prevent against accidental deletes

### Load Balancers Monitoring

* All Load Balancer metrics are directly pushed to CloudWatch metrics
* BackendConnectionErrors
* HealthyHostCount / UnHealthyHostCount
* HTTPCode_Backend_2XX: Successful request
* HTTPCode_Backend_3XX, redirected request
* **HTTPCode_ELB_4XX**: Client error codes
* **HTTPCode_ELB_5XX**: Server error codes generated by the load balancer
* Latency
* RequestCount
* **SurgeQueueLenght**: The total number of requests (HTTP listener) or connections (TCP listener) that are pending routing to a healthy instance. Helps to scale out ASG. Max value is 1024
* **SpilloverCount**: The total number of requests that were rejected because the surge queue is full

### Load Balancers Access Logs

* Access logs from Load Balancers can be stored in S3 and contain
  * Time
  * Client IP address
  * Latencies
  * Request paths
  * Server response
  * Trace Id
* Only pay for the S3 storage
* Helpful for compliance reason
* Helpful for keeping access data even after ELB or EC2 instances are terminated
* Access Logs are already encrypted

### Application Load Balancer Request Tracing

* Request tracing - Each HTTP request has an added custom header 'X-Amzn-Trace-Id'
  * This is useful in logs / distributed tracing platform to track a single request

### Load Balancer troubleshooting using metrics

* HTTP 400: BAD_REQUEST => The client sent a malformed request that does not meet HTTP specifications
* HTTP 503: Service Unavailable => Ensure that you have healthy instances in every Availability Zone that your load balancer is configured to respond in. Look for HealthyHostCount in CloudWatch
* HTTP 504: Gateway Timeout => Check if keep-alive settings on your EC2 instances are enabled and make sure that the keep-alive timeout is grater than the idle timeout settings of load balancer
* Set alarms & look at the documentation for troubleshooting: https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/ts-elb-error-message.html

### Auto Scaling Group

* The Goal of an Auto Scaling Group (ASG) is:
  * Scale out (add EC2 instances) to match an increased load
  * Scale in (remove EC2 instances) to match a decreased load
  * Ensure we have a minimum and a maximum number of machines running
  * Automatically Register new instances to a load balancer
* ASG have the attributes:
  * Launch configuration
    * AMI + Instance Type
    * EC2 User Data
    * EBS Volumes
    * Security Groups
    * SSH Key Pair
  * Min Size / Max Size / Initial Capacity
  * Network + Subnets Information
  * Load Balancer Information
  * Scaling Policies

#### Auto Scaling Alarms

* It is possible to scale an ASG based on CloudWatch alarms
* An Alarm monitors a metric (such as Average CPU)
* **Metrics are computed for the overall ASG instances**
* Scale in or out based on the Alarms

#### Auto Scaling New Rules

* Possible to define "better" auto scaling rules that are directly managed by EC2
  * Target Average CPU Usage
  * Numbeqr of requests on the ELB per instance
  * Average Network In
  * Average Network Out
* These rules are easier to set up and can make more sense

#### Auto Scaling Custom Metric

* It is possible to scale based on a custom metric (e.g.: number of connected users)
  1. Send Custom metric from application on EC2 to CloudWatch (PutMetric API)
  2. Create CloudWatch alarm to low / high values
  3. Use the CloudWatch alarm as the scaling policy for ASG

### Scaling Processes in ASG

* Launch: Add a new EC2 to the group, increasing the capacity
* Terminate: Removes an EC2 instance from the group, decreasing it's capacity
* HealthCheck: Checks the health of the instance
* ReplaceUnhealthy: Terminate unhealthy instances and re-create them
* AZRebalance: Balance the number of EC2 instances across AZ
* AlarmNotification: Accept notification from CloudWatch
* ScheduledActions: Performs scheduled actions that you create
* AddToLoadBalancer: Adds instances to the load balancer or target group
* **We can suspend these processes**

### ASG for SysOps

* ASG will not reboot unhealthy hosts for you
* Good to know CLI:
  * set-instance-health
  * terminate-instance-in-auto-scaling-group

#### Troubleshooting ASG issues

* < number of instances > instance(s) are already running. Launching EC2 instance failed.
  * The Auto Scaling group has reached the limit set by the DesiredCapacity parameter. Update ASG by providing a new value for the desired capacity
* Launching EC2 instances is failing:
  * The security group does not exist. SG might have been deleted
  * The key pair does not exist. It might've been deleted
* If the ASG fails to launch an instance for over 24 hours, it will automatically suspend the processes (administration suspension)

### CloudWatch Metrics for ASG

* The following metrics are available for ASG (opt-in):
  * **GroupMinSize**
  * **GroupMaxSize**
  * **GroupDesiredCapacity**
  * **GroupInServiceInstances**
  * **GroupPendingInstances**
  * **GroupStandbyInstances**
  * **GroupTerminatingInstances**
  * **GroupTotalInstances**
* You should enable metric collection to see these metrics
* Metrics are collected every 1 minute
* You can also monitor underlying EC2